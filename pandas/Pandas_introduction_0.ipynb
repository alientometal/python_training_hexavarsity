{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas  \n",
    "\n",
    "Pandas is a popular open-source data analysis and manipulation library for Python. Pandas stands for “Python Data Analysis Library ”. The name is derived from the term “panel data”, an econometrics term for multidimensional structured data sets. It provides easy-to-use and powerful tools for working with structured data such as tables and time series.\n",
    "\n",
    "Some advantages of Pandas include:\n",
    "\n",
    "* Data manipulation: Pandas provides powerful tools for filtering, transforming, and aggregating data.\n",
    "* Flexibility: Pandas can handle a wide range of data formats, including text files, CSV, Excel, SQL databases, and JSON.\n",
    "* Integration with other libraries: Pandas works seamlessly with other data science libraries in Python, such as NumPy and Matplotlib.\n",
    "* Time series analysis: Pandas has built-in support for working with time series data.\n",
    "\n",
    "Also:\n",
    "\n",
    "* Highly optimized for performance, with critical code paths written in Cython or C.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # import pandas library, and use pd as alias (this is a convention)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Structures\n",
    "\n",
    "Pandas data structures include Series and DataFrames. \n",
    "* A Series is a one-dimensional array-like object that can hold a variety of data types, such as integers, strings, and floats. \n",
    "* A DataFrame is a two-dimensional table-like data structure with rows and columns."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Series\n",
    "A Pandas Series is a one-dimensional labeled array that can hold any data type such as integers, floating-point numbers, strings, Python objects, etc. Each element in a Series has a label called the index, which is used to access the values of the Series. A Series is similar to a NumPy array, but it has an index that makes it more flexible and convenient to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a Series from a list\n",
    "s1 = pd.Series([3, 5, 1, 2, 7])\n",
    "print(s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a Series from a dictionary\n",
    "data = {'apples': 5, 'oranges': 2, 'bananas': 8, 'pears': 1}\n",
    "s2 = pd.Series(data)\n",
    "print(s2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a Series with custom index labels\n",
    "s3 = pd.Series([10, 20, 30, 40], index=['a', 'b', 'c', 'd'])\n",
    "print(s3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# access elements of a Series using index labels\n",
    "print(s2['apples'])   # output: 5\n",
    "print(s3[['a', 'c']]) # output: a    10, c    30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform arithmetic operations on Series\n",
    "s4 = s1 + s1\n",
    "print(s4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a boolean mask from a Series\n",
    "mask = s1 > 3\n",
    "print(mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter a Series using a boolean mask\n",
    "filtered_s1 = s1[mask]\n",
    "print(filtered_s1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply a function to each element of a Series\n",
    "s5 = s1.apply(lambda x: x ** 2)\n",
    "print(s5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame  \n",
    "A Pandas DataFrame is a two-dimensional labeled data structure that is used to store and manipulate tabular data. It consists of rows and columns, where each column can have a different data type. A DataFrame can be thought of as a collection of Series that share the same index. The rows are labeled by the index, and the columns are labeled by their names. DataFrame is the most commonly used Pandas data structure and can be thought of as a spreadsheet or SQL table. It provides powerful data manipulation and analysis functionalities, such as data indexing, selection, merging, grouping, and pivoting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a DataFrame from a dictionary\n",
    "data = {'name': ['Alice', 'Bob', 'Charlie', 'Dave'],\n",
    "        'age': [25, 30, 35, 40],\n",
    "        'country': ['USA', 'Canada', 'Australia', 'UK']}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a DataFrame from a CSV file\n",
    "df = pd.read_csv('data.csv')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a DataFrame from a NumPy array\n",
    "import numpy as np\n",
    "\n",
    "data = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "columns = ['A', 'B', 'C']\n",
    "\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a DataFrame from a list of dictionaries\n",
    "data = [{'name': 'Alice', 'age': 25, 'country': 'USA'},\n",
    "        {'name': 'Bob', 'age': 30, 'country': 'Canada'},\n",
    "        {'name': 'Charlie', 'age': 35, 'country': 'Australia'},\n",
    "        {'name': 'Dave', 'age': 40, 'country': 'UK'}]\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a JSON file into a DataFrame\n",
    "url = 'https://raw.githubusercontent.com/chrisalbon/simulated_datasets/master/data.json'\n",
    "\n",
    "# Load the first sheet of the JSON file into a data frame​\n",
    "df = pd.read_json(url, orient='columns')\n",
    "print(df.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data indexing and selection is a crucial aspect of data analysis. Pandas provides flexible ways to select subsets of data using methods such as loc and iloc.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Here are some common methods of the Pandas DataFrame:\n",
    "\n",
    "* `head()`: Returns the first n rows of the DataFrame. The default value of n is 5.\n",
    "* `tail()`: Returns the last n rows of the DataFrame. The default value of n is 5.\n",
    "* `info()`: Prints a summary of the DataFrame, including the column names, data types, and non-null values.\n",
    "* `describe()`: Generates descriptive statistics for numerical columns in the DataFrame, such as count, mean, and standard deviation.\n",
    "* `shape`: Returns a tuple representing the dimensions of the DataFrame, i.e., (number of rows, number of columns).\n",
    "* `columns`: Returns a list of the column names in the DataFrame.\n",
    "* `index`: Returns a list of the row labels or index values in the DataFrame.\n",
    "* `loc[]`: Allows you to access a group of rows and columns in the DataFrame using label-based indexing. For example, `df.loc[0:5, ['Name', 'Age']]` returns the rows from index 0 to 5, and the \"Name\" and \"Age\" columns.\n",
    "* `iloc[]`: Allows you to access a group of rows and columns in the DataFrame using integer-based indexing. For example `df.iloc[0:5, [0, 1]]` returns the first 5 rows and the first 2 columns.\n",
    "* `drop()`: Removes one or more rows or columns from the DataFrame. For example, df.drop('Age', axis=1) removes the \"Age\" column.\n",
    "* `fillna()`: Fills missing or NaN (Not a Number) values in the DataFrame with a specified value or method, such as the mean or median.\n",
    "* `groupby()`: Groups the DataFrame by one or more columns and applies a function, such as mean or sum, to each group.\n",
    "* `pivot_table()`: Creates a pivot table from the DataFrame, allowing you to summarize and analyze the data in different* ways.\n",
    "* `merge()`: Merges two or more DataFrames based on a common column or index.\n",
    "* `sort_values()`: Sorts the DataFrame by one or more columns in ascending or descending order.\n",
    "* `to_csv()`: Writes the DataFrame to a CSV file.\n",
    "* `plot()`: Creates a basic plot of the DataFrame, such as a line chart or histogram.\n",
    "\n",
    "These are just a few of the many methods available in Pandas DataFrame. Pandas offers a rich set of functions for data manipulation, aggregation, and visualization, making it a powerful tool for data analysis."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing, .loc[], and .iloc[]\n",
    "\n",
    "Pandas provides different methods to select rows and columns of data, the most important of which are loc and iloc. Understanding the differences between these methods is crucial for data manipulation in pandas. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing\n",
    "\n",
    "An `index` in pandas is like an address, that’s how any data point across the dataframe or series can be accessed. Rows and columns both have indexes, rows indices are called as index and for columns its general column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'age': [30, 2, 12, 4, 32, 33, 69],\n",
    "    'color': ['blue', 'green', 'red', 'white', 'gray', 'black', 'red'],\n",
    "    'food': ['Steak', 'Lamb', 'Mango', 'Apple', 'Cheese', 'Melon', 'Beans'],\n",
    "    'height': [165, 70, 120, 80, 180, 172, 150],\n",
    "    'score': [4.6, 8.3, 9.0, 3.3, 1.8, 9.5, 2.2],\n",
    "    'state': ['NY', 'TX', 'FL', 'AL', 'AK', 'TX', 'TX']\n",
    "    }\n",
    "\n",
    "index = ['Jane', 'Nick', 'Aaron', 'Penelope', 'Dean', 'Christina', 'Cornelia']\n",
    "\n",
    "df = pd.DataFrame(data, index=index)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## .loc[]\n",
    "\n",
    "`loc` is label-based data selection method which means that we have to pass the name of the row or column which we want to select. This method includes the last element of the range passed in it, unlike iloc. Along with that, it also uses the label names in the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select all rows for a specific column\n",
    "print(df.loc[: , 'color'])\n",
    "\n",
    "# Select all rows for multiple columns\n",
    "print(df.loc[:, ['age', 'color']])\n",
    "\n",
    "# Select multiple columns with specific rows\n",
    "print(df.loc[['Jane', 'Nick'], ['age', 'color']])\n",
    "\n",
    "# Select a range of rows for all columns\n",
    "print(df.loc['Nick':'Dean'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## .iloc[]\n",
    "\n",
    "On the other hand, `iloc` is an integer index-based method which means that we have to pass integer index in the method to select specific row/column. This method does not include the last element of the range passed in it unlike loc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select all rows for a specific column\n",
    "print(df.iloc[: , 1])\n",
    "\n",
    "# Select all rows for multiple columns\n",
    "print(df.iloc[:, [0, 1]])\n",
    "\n",
    "# Select multiple columns with specific rows\n",
    "print(df.iloc[[0, 1], [0, 1]])\n",
    "\n",
    "# Select a range of rows for all columns\n",
    "print(df.iloc[1:4])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Differences between .loc and .iloc\n",
    "\n",
    "- `loc` gets rows (or columns) with particular labels from the index.\n",
    "- `iloc` gets rows (or columns) at particular positions in the index (so it only takes integers).  \n",
    "  \n",
    "So `loc` is label-based data selecting method which means that we have to pass the name of the row or column which we want to select. This method includes the last element of the range. Unlike `loc`, in `iloc`, we have to pass the integer index in the method to select specific row/column. This method does not include the last element of the range."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas Axis Manipulation \n",
    "\n",
    "### Axis 0 and Axis 1\n",
    "In pandas, `axis=0` represents rows (running vertically downwards across rows) and `axis=1` represents columns (running horizontally from left to right across columns). \n",
    "\n",
    "Always remember, `axis=0` will act on all the **ROWS** in each **COLUMN**, `axis=1` will act on all the **COLUMNS** in each **ROW**. This becomes very important when you want to add rows, delete rows, or apply some calculation down a column or across a row."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and Writing Data\n",
    "Pandas provides functions for reading and writing data in a variety of formats. You can read data from a CSV file and write it to an Excel file, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from a CSV file\n",
    "df = pd.read_csv('data.csv')\n",
    "\n",
    "# Write data to an Excel file\n",
    "df.to_excel('data.xlsx', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory usage\n",
    "Pandas provides functionality to explicitly check the memory usage of a DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info(memory_usage='deep')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, `deep` provides the most accurate report of the memory usage, accounting for the true memory usage of all components of the DataFrame.\n",
    "\n",
    "However, the memory consumption of a DataFrame is not only determined by the number of items but also the data type of the items. For instance, the data type `int64` consumes more memory than `int8`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform operation to reduce memory usage\n",
    "df['column_name'] = df['column_name'].astype('int8')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with Large Datasets\n",
    "You'll likely encounter datasets that are too large to fit into memory. In such cases, Pandas provides several techniques to handle this scenario:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Chunking: Read data in chunks small enough to fit into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunksize = 10 ** 6  # Tune this value to best match your memory availability\n",
    "for chunk in pd.read_csv(\"large_dataset.csv\", chunksize=chunksize):\n",
    "    process(chunk)  # define a function to process your data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- DTypes: Minimize memory usage by specifying or converting data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv', dtype={'column1': 'int8', 'column2': 'float32'})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploratory data analysis is an important step in understanding the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the summary statistics of the DataFrame\n",
    "df.describe()\n",
    "\n",
    "# Get the unique values in a column\n",
    "df['colum_name'].unique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptive Statistics with Pandas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean, median, mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pandas series\n",
    "data = pd.Series(np.random.randint(low=0, high=10, size=20))\n",
    "\n",
    "# calculate mean, median, and mode\n",
    "mean = data.mean()\n",
    "median = data.median()\n",
    "mode = data.mode()[0]\n",
    "\n",
    "print(\"Mean:\", mean)\n",
    "print(\"Median:\", median)\n",
    "print(\"Mode:\", mode)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variance and standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate variance and standard deviation\n",
    "variance = data.var()\n",
    "std_deviation = data.std()\n",
    "\n",
    "print(\"Variance:\", variance)\n",
    "print(\"Standard deviation:\", std_deviation)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skewness and kurtosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skewness = data.skew()\n",
    "kurtosis = data.kurtosis()\n",
    "\n",
    "print(\"Skewness:\", skewness)\n",
    "print(\"Kurtosis:\", kurtosis)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation\n",
    "Pairwise correlation of columns: Exclude NA/null values when computing correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create two pandas series\n",
    "x = pd.Series(np.random.randint(low=0, high=10, size=20))\n",
    "y = pd.Series(np.random.randint(low=0, high=10, size=20))\n",
    "\n",
    "# calculate correlation\n",
    "correlation = x.corr(y)\n",
    "\n",
    "print(\"Correlation:\", correlation)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting values\n",
    "Value counts: Compute a histogram of a 1D array (Series)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pandas dataframe\n",
    "df = pd.DataFrame({\n",
    "    'name': ['Alice', 'Bob', 'Charlie', 'David', 'Ella', 'Frank'],\n",
    "    'age': [20, 25, 30, 35, 40, 45],\n",
    "    'gender': ['F', 'M', 'M', 'M', 'F', 'M']\n",
    "})\n",
    "\n",
    "# count values in a column\n",
    "gender_counts = df['gender'].value_counts()\n",
    "\n",
    "print(gender_counts)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantile-based discretization function: Divide data into equal-sized buckets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pandas series\n",
    "data = pd.Series(np.random.randint(low=0, high=10, size=20))\n",
    "\n",
    "print(pd.qcut(data, 4))  # Quartile cut"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Material\n",
    "\n",
    "Topics we are covering on next material:\n",
    "\n",
    "* **Data cleaning and preparation** are essential steps in data analysis. Pandas provides functions for handling missing data, removing duplicates, and converting data types.\n",
    "\n",
    "* **Data aggregation and grouping** involve summarizing data based on one or more variables. Pandas provides a groupby function for grouping data by one or more columns and performing various operations on the resulting groups.\n",
    "\n",
    "* **Merging and joining data** involve combining data from different sources into a single dataset. Pandas provides functions for merging and joining data based on common columns or indices.\n",
    "\n",
    "* **Time series analysis** is a specialized area of data analysis that deals with data that is indexed by time. Pandas provides functions for working with time series data, such as resampling, rolling, and shifting.\n",
    "\n",
    "* **Reshaping and pivoting data** involve transforming data from one format to another. Pandas provides functions for pivoting and reshaping data, such as melt, pivot, stack, and unstack."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Content created by [**Carlos Cruz-Maldonado**](https://www.linkedin.com/in/carloscruzmaldonado/).  \n",
    "> I am available to answer any questions or provide further assistance.   \n",
    "> Feel free to reach out to me at any time.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "personal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
